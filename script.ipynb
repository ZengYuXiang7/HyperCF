{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def GCN(self, ulat, ilat, adj, tpAdj):\n",
    "    ulats = [ulat]\n",
    "    ilats = [ilat]\n",
    "    for i in range(args.gcn_hops):\n",
    "        temulat = tf.sparse.sparse_dense_matmul(adj, ilats[-1])\n",
    "        temilat = tf.sparse.sparse_dense_matmul(tpAdj, ulats[-1])\n",
    "        ulats.append(temulat)\n",
    "        ilats.append(temilat)\n",
    "    return tf.add_n(ulats[1:]), tf.add_n(ilats[1:])\n",
    "\n",
    "def prepareKey(self, nodeEmbed):\n",
    "    K = NNs.getOrDefineParam('KMapping', [args.latdim, args.latdim], reg=True, reuse=True)\n",
    "    key = tf.reshape(nodeEmbed @ K, [-1, args.att_head, args.latdim//args.att_head])\n",
    "    key = tf.transpose(key, perm=[1, 0, 2]) # Head * N * d'(lowrank)\n",
    "    return key\n",
    "\n",
    "# def makeView(self, a, b):\n",
    "# \treturn tf.nn.dropout(a, self.keepRate), tf.nn.dropout(b, self.keepRate)\n",
    "\n",
    "def propagate(self, lats, key, hyper):\n",
    "    V = NNs.getOrDefineParam('VMapping', [args.latdim, args.latdim], reg=True, reuse=True)\n",
    "    lstLat = tf.reshape(lats[-1] @ V, [-1, args.att_head, args.latdim // args.att_head])\n",
    "    lstLat = tf.transpose(lstLat, perm=[1, 2, 0]) # Head * d' * N\n",
    "    temlat1 = lstLat @ key # Head * d' * d'\n",
    "    hyper = tf.reshape(hyper, [-1, args.att_head, args.latdim//args.att_head])\n",
    "    hyper = tf.transpose(hyper, perm=[1, 2, 0]) # Head * d' * E\n",
    "    temlat1 = tf.reshape(temlat1 @ hyper, [args.latdim, -1]) # d * E\n",
    "    temlat2 = FC(temlat1, args.hyperNum, activation=self.actFunc) + temlat1\n",
    "    temlat3 = FC(temlat2, args.hyperNum, activation=self.actFunc) + temlat2 # d * E\n",
    "\n",
    "    preNewLat = tf.reshape(tf.transpose(temlat3) @ V, [-1, args.att_head, args.latdim//args.att_head])\n",
    "    preNewLat = tf.transpose(preNewLat, [1, 0, 2])# Head * E * d'\n",
    "    preNewLat = hyper @ preNewLat # Head * d'(lowrank) * d'(embed)\n",
    "    newLat = key @ preNewLat # Head * N * d'\n",
    "    newLat = tf.reshape(tf.transpose(newLat, [1, 0, 2]), [-1, args.latdim])\n",
    "    lats.append(newLat)\n",
    "\n",
    "def meta(self, hyper):\n",
    "    hyper_mean = tf.reduce_mean(hyper, axis=0, keep_dims=True)\n",
    "    hyper = hyper_mean\n",
    "    W1 = tf.reshape(FC(hyper, args.latdim * args.latdim, useBias=True, reg=True, name='W1_gen', reuse=True), [args.latdim, args.latdim])\n",
    "    b1 = FC(hyper, args.latdim, useBias=True, reg=True, name='b1_gen', reuse=True)\n",
    "    def mapping(key):\n",
    "        ret = Activate(key @ W1 + b1, 'leakyRelu')\n",
    "        # ret = Activate(lat @ W2 + b2, 'leakyRelu')\n",
    "        return ret\n",
    "    return mapping\n",
    "\n",
    "def label(self, usrKey, itmKey, uHyper, iHyper):\n",
    "    uMapping = self.meta(uHyper)\n",
    "    iMapping = self.meta(iHyper)\n",
    "    ulat = uMapping(usrKey)\n",
    "    ilat = iMapping(itmKey)\n",
    "    lat = tf.concat([ulat, ilat], axis=-1)\n",
    "    lat = FC(lat, args.latdim, activation='leakyRelu', useBias=True, reg=True) + ulat + ilat\n",
    "    ret = tf.reshape(FC(lat, 1, activation='sigmoid', useBias=True, reg=True), [-1])\n",
    "    return ret\n",
    "\n",
    "def ours(self):\n",
    "    uEmbed_ini = NNs.defineParam('uEmbed_ini', [args.user, args.latdim], reg=True)\n",
    "    iEmbed_ini = NNs.defineParam('iEmbed_ini', [args.item, args.latdim], reg=True)\n",
    "    uEmbed_gcn, iEmbed_gcn = self.GCN(uEmbed_ini, iEmbed_ini, self.adj, self.tpAdj)\n",
    "    uEmbed0 = uEmbed_ini + uEmbed_gcn\n",
    "    iEmbed0 = iEmbed_ini + iEmbed_gcn\n",
    "    self.gcnNorm = (tf.reduce_sum(tf.reduce_sum(tf.square(uEmbed_gcn), axis=-1)) + tf.reduce_sum(tf.reduce_sum(tf.square(iEmbed_gcn), axis=-1))) / 2\n",
    "    self.iniNorm = (tf.reduce_sum(tf.reduce_sum(tf.square(uEmbed_ini), axis=-1)) + tf.reduce_sum(tf.reduce_sum(tf.square(iEmbed_ini), axis=-1))) / 2\n",
    "\n",
    "    uHyper = NNs.defineParam('uHyper', [args.hyperNum, args.latdim], reg=True)\n",
    "    iHyper = NNs.defineParam('iHyper', [args.hyperNum, args.latdim], reg=True)\n",
    "    uKey = self.prepareKey(uEmbed0)\n",
    "    iKey = self.prepareKey(iEmbed0)\n",
    "\n",
    "    ulats = [uEmbed0]\n",
    "    ilats = [iEmbed0]\n",
    "    for i in range(args.gnn_layer):\n",
    "        self.propagate(ulats, uKey, uHyper)\n",
    "        self.propagate(ilats, iKey, iHyper)\n",
    "\n",
    "    ulat = tf.add_n(ulats)\n",
    "    ilat = tf.add_n(ilats)\n",
    "\n",
    "    pckUlat = tf.nn.embedding_lookup(ulat, self.uids)\n",
    "    pckIlat = tf.nn.embedding_lookup(ilat, self.iids)\n",
    "    preds = tf.reduce_sum(pckUlat * pckIlat, axis=-1)\n",
    "\n",
    "    idx = self.adj.indices\n",
    "    usrs, itms = tf.nn.embedding_lookup(idx[:, 0], self.edgeids), tf.nn.embedding_lookup(idx[:, 1], self.edgeids)\n",
    "    uKey = tf.reshape(tf.transpose(uKey, perm=[1, 0, 2]), [-1, args.latdim])# N * d\n",
    "    iKey = tf.reshape(tf.transpose(iKey, perm=[1, 0, 2]), [-1, args.latdim])\n",
    "    usrKey = tf.nn.embedding_lookup(uKey, usrs)\n",
    "    itmKey = tf.nn.embedding_lookup(iKey, itms)\n",
    "    scores = self.label(usrKey, itmKey, uHyper, iHyper)\n",
    "    _preds = tf.reduce_sum(tf.nn.embedding_lookup(uEmbed0, usrs) * tf.nn.embedding_lookup(iEmbed0, itms), axis=-1)\n",
    "\n",
    "    self.pck_preds = _preds\n",
    "    self.pck_labels = scores\n",
    "\n",
    "    halfNum = tf.shape(scores)[0] // 2\n",
    "    fstScores = tf.slice(scores, [0], [halfNum])\n",
    "    scdScores = tf.slice(scores, [halfNum], [-1])\n",
    "    fstPreds = tf.slice(_preds, [0], [halfNum])\n",
    "    scdPreds = tf.slice(_preds, [halfNum], [-1])\n",
    "    sslLoss = tf.reduce_sum(tf.maximum(0.0, 1.0 - (fstPreds - scdPreds) * args.mult * (fstScores - scdScores)))\n",
    "\n",
    "    return preds, sslLoss, ulat, ilat\n",
    "\n",
    "def tstPred(self, ulat, ilat):\n",
    "    pckUlat = tf.nn.embedding_lookup(ulat, self.uids)\n",
    "    allPreds = pckUlat @ tf.transpose(ilat)\n",
    "    allPreds = allPreds * (1 - self.trnPosMask) - self.trnPosMask * 1e8\n",
    "    vals, locs = tf.nn.top_k(allPreds, args.shoot)\n",
    "    return locs\n",
    "\n",
    "def prepareModel(self):\n",
    "    self.keepRate = tf.placeholder(dtype=tf.float32, shape=[])\n",
    "    NNs.leaky = args.leaky\n",
    "    self.actFunc = 'leakyRelu'\n",
    "    adj = self.handler.trnMat\n",
    "    idx, data, shape = transToLsts(adj, norm=True)\n",
    "    self.adj = tf.sparse.SparseTensor(idx, data, shape)\n",
    "\n",
    "    idx, data, shape = transToLsts(transpose(adj), norm=True)\n",
    "    self.tpAdj = tf.sparse.SparseTensor(idx, data, shape)\n",
    "\n",
    "\n",
    "    self.uids = tf.placeholder(name='uids', dtype=tf.int32, shape=[None])\n",
    "    self.iids = tf.placeholder(name='iids', dtype=tf.int32, shape=[None])\n",
    "    self.edgeids = tf.placeholder(name='edgeids', dtype=tf.int32, shape=[None])\n",
    "    self.trnPosMask = tf.placeholder(name='trnPosMask', dtype=tf.float32, shape=[None, args.item])\n",
    "\n",
    "    self.preds, sslLoss, ulat, ilat = self.ours()\n",
    "    self.topLocs = self.tstPred(ulat, ilat)\n",
    "\n",
    "    sampNum = tf.shape(self.uids)[0] // 2\n",
    "    posPred = tf.slice(self.preds, [0], [sampNum])\n",
    "    negPred = tf.slice(self.preds, [sampNum], [-1])\n",
    "    self.preLoss = tf.reduce_sum(tf.maximum(0.0, 1.0 - (posPred - negPred))) / args.batch\n",
    "    self.regLoss = args.reg * Regularize()\n",
    "    self.sslLoss = args.ssl_reg * sslLoss\n",
    "    self.loss = self.preLoss + self.regLoss + self.sslLoss\n",
    "\n",
    "    globalStep = tf.Variable(0, trainable=False)\n",
    "    learningRate = tf.train.exponential_decay(args.lr, globalStep, args.decay_step, args.decay, staircase=True)\n",
    "    self.optimizer = tf.train.AdamOptimizer(learningRate).minimize(self.loss, global_step=globalStep)\n",
    "\n",
    "def sampleTrainBatch(self, batIds, labelMat):\n",
    "    temLabel = labelMat[batIds].toarray()\n",
    "    batch = len(batIds)\n",
    "    temlen = batch * 2 * args.sampNum\n",
    "    uLocs = [None] * temlen\n",
    "    iLocs = [None] * temlen\n",
    "    cur = 0\n",
    "    for i in range(batch):\n",
    "        posset = np.reshape(np.argwhere(temLabel[i]!=0), [-1])\n",
    "        sampNum = min(args.sampNum, len(posset))\n",
    "        if sampNum == 0:\n",
    "            poslocs = [np.random.choice(args.item)]\n",
    "            neglocs = [poslocs[0]]\n",
    "        else:\n",
    "            poslocs = np.random.choice(posset, sampNum)\n",
    "            neglocs = negSamp(temLabel[i], sampNum, args.item)\n",
    "        for j in range(sampNum):\n",
    "            posloc = poslocs[j]\n",
    "            negloc = neglocs[j]\n",
    "            uLocs[cur] = uLocs[cur+temlen//2] = batIds[i]\n",
    "            iLocs[cur] = posloc\n",
    "            iLocs[cur+temlen//2] = negloc\n",
    "            cur += 1\n",
    "    uLocs = uLocs[:cur] + uLocs[temlen//2: temlen//2 + cur]\n",
    "    iLocs = iLocs[:cur] + iLocs[temlen//2: temlen//2 + cur]\n",
    "\n",
    "    edgeSampNum = int(args.edgeSampRate * args.edgeNum)\n",
    "    if edgeSampNum % 2 == 1:\n",
    "        edgeSampNum += 1\n",
    "    edgeids = np.random.choice(args.edgeNum, edgeSampNum)\n",
    "    return uLocs, iLocs, edgeids\n",
    "\n",
    "def trainEpoch(self):\n",
    "    num = args.user\n",
    "    sfIds = np.random.permutation(num)[:args.trnNum]\n",
    "    epochLoss, epochPreLoss, epochsslLoss = [0] * 3\n",
    "    num = len(sfIds)\n",
    "    steps = int(np.ceil(num / args.batch))\n",
    "\n",
    "    for i in range(steps):\n",
    "        st = i * args.batch\n",
    "        ed = min((i+1) * args.batch, num)\n",
    "        batIds = sfIds[st: ed]\n",
    "\n",
    "        target = [self.optimizer, self.preLoss, self.regLoss, self.loss, self.sslLoss, self.iniNorm, self.gcnNorm]\n",
    "        feed_dict = {}\n",
    "        uLocs, iLocs, edgeids = self.sampleTrainBatch(batIds, self.handler.trnMat)\n",
    "        feed_dict[self.uids] = uLocs\n",
    "        feed_dict[self.iids] = iLocs\n",
    "        feed_dict[self.keepRate] = args.keepRate\n",
    "        feed_dict[self.edgeids] = edgeids\n",
    "\n",
    "        res = self.sess.run(target, feed_dict=feed_dict, options=config_pb2.RunOptions(report_tensor_allocations_upon_oom=True))\n",
    "\n",
    "        preLoss, regLoss, loss, sslLoss, iniNorm, gcnNorm = res[1:]\n",
    "\n",
    "        epochLoss += loss\n",
    "        epochPreLoss += preLoss\n",
    "        epochsslLoss += sslLoss\n",
    "        \n",
    "        log('Step %d/%d: loss = %.2f, regLoss = %.2f, sslLoss = %.2f         ' % (i, steps, loss, regLoss, sslLoss), save=False, oneline=True)\n",
    "    ret = dict()\n",
    "    ret['Loss'] = epochLoss / steps\n",
    "    ret['preLoss'] = epochPreLoss / steps\n",
    "    ret['sslLoss'] = epochsslLoss / steps\n",
    "    return ret\n",
    "\n",
    "def testEpoch(self):\n",
    "    epochRecall, epochNdcg = [0] * 2\n",
    "    ids = self.handler.tstUsrs\n",
    "    num = len(ids)\n",
    "    tstBat = args.batch\n",
    "    steps = int(np.ceil(num / tstBat))\n",
    "    tstNum = 0\n",
    "    for i in range(steps):\n",
    "        st = i * tstBat\n",
    "        ed = min((i+1) * tstBat, num)\n",
    "        batIds = ids[st: ed]\n",
    "        feed_dict = {}\n",
    "\n",
    "        trnPosMask = self.handler.trnMat[batIds].toarray()\n",
    "        feed_dict[self.uids] = batIds\n",
    "        feed_dict[self.trnPosMask] = trnPosMask\n",
    "        feed_dict[self.keepRate] = 1.0\n",
    "        topLocs = self.sess.run(self.topLocs, feed_dict=feed_dict, options=config_pb2.RunOptions(report_tensor_allocations_upon_oom=True))\n",
    "\n",
    "        recall, ndcg = self.calcRes(topLocs, self.handler.tstLocs, batIds)\n",
    "        epochRecall += recall\n",
    "        epochNdcg += ndcg\n",
    "        log('Steps %d/%d: recall = %.2f, ndcg = %.2f          ' % (i, steps, recall, ndcg), save=False, oneline=True)\n",
    "    ret = dict()\n",
    "    ret['Recall'] = epochRecall / num\n",
    "    ret['NDCG'] = epochNdcg / num\n",
    "    return ret\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9533614ab79ccc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
